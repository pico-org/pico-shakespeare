{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Oj6gBidzW2W_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9ROEofS3Y4FV"
      },
      "outputs": [],
      "source": [
        "def get_config():\n",
        "  return {\n",
        "      \"block_size\": 8,\n",
        "      \"batch_size\": 32,\n",
        "      \"vocab_size\":65,\n",
        "      \"max_tokens\":1000,\n",
        "      \"n_embd\":32,\n",
        "      'lr':1e-3,\n",
        "      'epochs':5000,\n",
        "      'head_size':8,\n",
        "      'num_head':4\n",
        "  }\n",
        "config = get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mdPCxmNrRmYl"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/input.txt\",'r',encoding='utf-8') as f:\n",
        "  text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKEXV3s2R1GV",
        "outputId": "4e4666ad-d734-4241-ae1c-94fc568f58ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total len of the text 1115394\n"
          ]
        }
      ],
      "source": [
        "print(f\"total len of the text {len(text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpFgFgDzR79Z",
        "outputId": "733bc5a9-b646-4fea-ed84-4f3f9384df2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vt0k6zxhSB94"
      },
      "outputs": [],
      "source": [
        "def construct_vocabulary(text):\n",
        "  chars = sorted(list(set(text)))\n",
        "  vocab_size = len(chars)\n",
        "  return (vocab_size,chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PGisAxMvTDA0"
      },
      "outputs": [],
      "source": [
        "vocab_size,chars = construct_vocabulary(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgtIwPbjTEpT",
        "outputId": "7eab5f90-cb4e-4a28-a164-121d18cc6740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ],
      "source": [
        "print(\"\".join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2qwaizNQTOM7"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self,chars):\n",
        "    print(\"started building the vocab...\")\n",
        "    self.stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "    self.itos = {i:ch for i,ch in enumerate(chars)}\n",
        "    print(f\"done...\")\n",
        "\n",
        "  def encode(self,s):\n",
        "    \"input: a string\"\n",
        "    return [self.stoi[c] for c in s]\n",
        "\n",
        "  def decode(self,l):\n",
        "    \"input: a list\"\n",
        "    return \"\".join(self.itos[i] for i in l)\n",
        "\n",
        "  def build_(self,text):\n",
        "    return torch.tensor(self.encode(text),dtype = torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h82_rB7VT8Jt",
        "outputId": "0a5d606c-8a1f-4877-bf2f-3d357292c975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "started building the vocab...\n",
            "done...\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1nwKy2uWrC1"
      },
      "outputs": [],
      "source": [
        "data = tokenizer.build_(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZwcNyFz9X7ls"
      },
      "outputs": [],
      "source": [
        "class Train_Test_Split:\n",
        "  def __init__(self,train_per):\n",
        "    self.train_per = train_per\n",
        "\n",
        "  def __call__(self,data):\n",
        "    n = int(self.train_per*len(data))\n",
        "    train_data = data[:n]\n",
        "    val_data = data[n:]\n",
        "    return train_data,val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sp_QUbUiYnuS"
      },
      "outputs": [],
      "source": [
        "tts = Train_Test_Split(0.9)\n",
        "train_data,val_data = tts(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fxaM_6yNY0Di"
      },
      "outputs": [],
      "source": [
        "x = train_data[:config['batch_size']]\n",
        "y = train_data[1:config['batch_size']+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Jtyf3Pvqa0zh"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "class Batching:\n",
        "  def __init__(self,train_data,val_data,config):\n",
        "    self.train_data = train_data\n",
        "    self.val_data = val_data\n",
        "    self.batch_size = config['batch_size']\n",
        "    self.block_size = config['block_size']\n",
        "\n",
        "  def __call__(self,split):\n",
        "    self.split = split\n",
        "    data = self.train_data if self.split == \"train\" else self.val_data\n",
        "    ix = torch.randint(0,len(data)-self.block_size,(self.batch_size,))\n",
        "    x = torch.stack([data[i:i+self.block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+self.block_size+1] for i in ix])\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CQ58AMctdfli"
      },
      "outputs": [],
      "source": [
        "batching = Batching(train_data,val_data,config)\n",
        "x,y = batching(\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3sBVbQbHfK1J"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.vocab_size = config['vocab_size']\n",
        "    self.token_emb_table = nn.Embedding(self.vocab_size,self.vocab_size)\n",
        "\n",
        "  def forward(self,idx,target=None):\n",
        "    logits = self.token_emb_table(idx)\n",
        "\n",
        "    if target is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B,T,C = logits.shape\n",
        "      logits = logits.view(B*T,C)\n",
        "      target = target.view(-1)\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      loss = criterion(logits,target)\n",
        "    return logits,loss\n",
        "\n",
        "  def generate(self,idx,config):\n",
        "    for i in range(config['max_tokens']):\n",
        "      logits,_ = self(idx)\n",
        "      logits = logits[:,-1,:]\n",
        "      probs = F.softmax(logits,dim=1)\n",
        "      idx_next = torch.multinomial(probs,num_samples=1)\n",
        "      idx = torch.cat((idx,idx_next),dim = 1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fQFA1weylYdY"
      },
      "outputs": [],
      "source": [
        "blm = BigramLanguageModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyw0aFcGmH_p",
        "outputId": "9706f0da-ef5d-4028-ec3f-ec65b096fed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "JLg,3D&OM .3YCjfolRwqXaDyttW!GmaUT-IIvuZV?sYfjzUvTQ3RwL ?etyLeg.COHW\n",
            "Ri$ELkJMXpBEX;-G&Orl!bcH ;cq.z,rbyQZoN:QVT:cVOtkTLhuMYe-gqGhTxDlqYBkLDJnAsLJOVeJYD\n",
            "J:r:HHESAbIqa!SKO.zJkSD$AzSQemsLuMElSU\n",
            "NjOaXnHFzYtIIu&MENop?pNDfSegXRwp!,CDWBSCtA&O:y,hc?bSFm!,NEbD UXzKGW$b?K'LXW$hCwBFQpbfJGtiMFfKLNrHRml$ZWxCm:Q.NlnkdhdwqRDSG.HmBISxRKt&fcEnjSDyhwKwlutO;PRWB,Fb'KMW$ZWoALAtNau'eqaIHbsbI3l-zx,bpoqYiSKpRJo':TgEgKl-b;MRw$E'zlDaec?ZfENG3?-caHHWlHa.3j.oNeiuRw?'Nq HqG ?qnwlA d.CodJzLV.v!EGhTnICnRN&WW,bZUiFkT.kTIhOh,;vGyjyeijojkSZAkmTUCF$nJoyiS!kgQ\n",
            "-IF,JD,UdyatSVhykKI?QvCnZVo?esSf X3Pmx?WWbLfxmM3dG\n",
            ":eJ:AuD,.kf&Pw$kT.ZW$sS cGgKQz.K.re-uOuFKpOoCDx-Q.zs\n",
            "xG;uZSK\n",
            "jRvcGpB\n",
            "jpboh,$TnKYSKVgKY;PqZwt TlLemMTlRDCQzuFB?r N$:T.G&?b!KpoiKCBreujOFqZRrjOWysEc;lp'!TnJMAbvEz'euZWVDdvkVxWCtxaZZ.CoHAVemSKJ-id?,mx,lGbfTxBr,.,;PgUPZBkcHZ-NsrH!JNvdZWqc?' ?VEpbZW$P:3.zvhEPnx,;vYQ\n",
            "IvPSSBgvDo&Aksyd-B\n",
            "Dbfj:hoXhMKimFaxKJmx3tjJjdka;MEXjX3J3hgj.J:dZPqJ-jWB isrhFJOGNt ,xH! ;n ey'IuukSnlCW\n",
            "jk! iTN? hDFyBI Wlm'z&,MEXKCjJpbLcY;YDqWbIhhhmHHrYf\n"
          ]
        }
      ],
      "source": [
        "idx = torch.zeros((1,1),dtype = torch.long)\n",
        "print(tokenizer.decode(blm.generate(idx,config)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bElN9mElULqb",
        "outputId": "568387dd-151c-47b6-dca6-13a928ad962a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.7732717990875244\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = torch.optim.AdamW(blm.parameters(),lr = 1e-3)\n",
        "batching = Batching(train_data,val_data,config)\n",
        "for steps in range(1000):\n",
        "    xb,yb = batching(\"train\")\n",
        "\n",
        "    logits,loss = blm(xb,yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAbl9sETVxHS",
        "outputId": "42f16994-6026-419b-dd0a-7e9cca55913c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "BSpbweglA!QF:\n",
            "waDKxh,XRIo3Y,W'zVeiLe,,XxL:K.ziedg&I!ColP,pLkYxY Letfn&boqYRD&'dG?'tnDc\n",
            "RSldGQF aJOHqqaw?KQ&Se-wr,J.SKeBI:\n",
            "I$WutjSq:g&n,FzRDwh-Q.xpbvrit'\n",
            "Jc m.!;rY$!haw:r'- UwaxuZng,p'T-gEItduGtvC&ml.\n",
            "JklaVS!RwnKs33IALg?WPhmujOn BY&PSTnQ3?'kb:OpanV\n",
            "by$W$ERway,LgcTFMSHZKO\n",
            "Q.?Hap'Hqfo\n",
            "Je,;?K,CsLyRrQ.MAhMbojyRxhmyw?o\n",
            "tticarzd:wenIfejXx,DwxEHdeBBD:TSCBCURDoXcutMBH3dakph;l!B\n",
            "PMjoCUA HZswigKINTnBEX;ybsNGtNo\n",
            "j$'zWEtk,r.zRNoNRrq'zp.e,pRd-vP;Cdg&-\n",
            "Lfj-UdariRDI-g whesX;QxBmheAWuZ nokh3j,F:QG'aKO&Pn eJp\n",
            "JzivCtnG,XjRldG&xThthMxzuMBThovu$htot:;sLPshmWEExOVVLAm sLeBnAEcRtL\n",
            "cZpoNAOV!pimkwidFzU!Ih.I;aiPYR d.CdoC mBSC.AnaqpaQ3deGtoVFabsOIIGoCOAuonEXLPnZnfLY;&MiriGAWQepl-AUDX33jR $rlSGD\n",
            "totNTUYBI\n",
            "OJVDg\n",
            "r T.CEIEcEJ&w,IfRwlM.EGS Kp$ZWBqfRYyF$TKTupB3cEXju;SxQURShvvDxN:hFyC:PgE:eFq!my?LkTII?LgjBA:IZUr:BHWB MyfSfo3cYDHimpAn?OofUL\n",
            "P irjeFH\n",
            "lyg$WdePX uZOQ.DTlo,J&w.zYQUk pGXjD Ve! szeBoopeBDqvLgEiSKJIfO:JFqqXaIX3IXyfoiPwigmUqcNlav.jO\n",
            "AzgUT;JCRIEQe3jOrNtybRieBMThqbt'zN&UABoCYrXm-pBYW.euFccWq!T:hbPYRwpoXSe ?onMren\n"
          ]
        }
      ],
      "source": [
        "idx = torch.zeros((1,1),dtype = torch.long)\n",
        "print(tokenizer.decode(blm.generate(idx,config)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0ZbM0dwyykN"
      },
      "source": [
        "# The Mathematical trick in self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzyk4GeoWKKT",
        "outputId": "7660d19e-6090-496d-d749-b22df6e03658"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnLiIvo50Fu_",
        "outputId": "7154e0d8-29d8-4452-963c-cbadd355f1af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.3596, -0.9152],\n",
              "         [ 0.6258,  0.0255],\n",
              "         [ 0.9545,  0.0643],\n",
              "         [ 0.3612,  1.1679],\n",
              "         [-1.3499, -0.5102],\n",
              "         [ 0.2360, -0.2398],\n",
              "         [-0.9211,  1.5433]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.2858,  0.9651],\n",
              "         [-2.0371,  0.4931],\n",
              "         [ 1.4870,  0.5910],\n",
              "         [ 0.1260, -1.5627],\n",
              "         [-1.1601, -0.3348],\n",
              "         [ 0.4478, -0.8016],\n",
              "         [ 1.5236,  2.5086]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 1.0101,  0.1215],\n",
              "         [ 0.1584,  1.1340],\n",
              "         [-1.1539, -0.2984],\n",
              "         [-0.5075, -0.9239],\n",
              "         [ 0.5467, -1.4948],\n",
              "         [-1.2057,  0.5718],\n",
              "         [-0.5974, -0.6937]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.3514, -0.2759],\n",
              "         [-1.5108,  2.1048],\n",
              "         [ 2.7630, -1.7465],\n",
              "         [ 1.4516, -1.5103],\n",
              "         [ 0.8212, -0.2115],\n",
              "         [ 0.7789,  1.5333],\n",
              "         [ 1.6097, -0.4032]]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZVilz17azGMD"
      },
      "outputs": [],
      "source": [
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    x_prev = x[b,:t+1]\n",
        "    xbow[b,t] = torch.mean(x_prev,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hU3HL4v732El"
      },
      "outputs": [],
      "source": [
        "wei = torch.tril(torch.ones(T,T))\n",
        "wei = wei / wei.sum(1,True)\n",
        "xbow2 = wei@x # (T,T)@(B,T,C)--> (B,T,C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTC1w8Qt45IJ"
      },
      "source": [
        "### Trick-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4XoU-1m1y5m",
        "outputId": "708e0615-e19d-43d0-8ba5-70dc95e891f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "\n",
            "\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "\n",
            "\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3,3))\n",
        "a = a / torch.sum(a,1,keepdim = True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a@b\n",
        "print(a)\n",
        "print(\"\\n\")\n",
        "print(b)\n",
        "print(\"\\n\")\n",
        "print(c)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUSrk21h6Mox"
      },
      "source": [
        "### Trick-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1cHurbV2bVw",
        "outputId": "3e7dd015-4a66-4c7c-fd13-dc5ee36e5b8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 0.1735, -0.0649],\n",
              "         [ 0.1685,  0.3348],\n",
              "         [-0.1621,  0.1765],\n",
              "         [-0.2312, -0.0436],\n",
              "         [-0.1015, -0.2855],\n",
              "         [-0.2593, -0.1630],\n",
              "         [-0.3015, -0.2293]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.4985, -0.5395],\n",
              "         [ 0.4954,  0.3420],\n",
              "         [ 1.0623, -0.1802],\n",
              "         [ 1.1401, -0.4462],\n",
              "         [ 1.0870, -0.4071],\n",
              "         [ 1.0430, -0.1299],\n",
              "         [ 1.1138, -0.1641]]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0,float('-inf'))\n",
        "wei = F.softmax(wei,dim = 1)\n",
        "xbow3 = wei@x\n",
        "xbow3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpcCHLYt-ONW"
      },
      "source": [
        "## Self-Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLr4-te08__Y",
        "outputId": "676f4d3e-faf5-4d74-d1cf-5b0b3d3603e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32\n",
        "x = torch.randn(B,T,C) #shape (B,T,C)\n",
        "\n",
        "head_size = 16\n",
        "key = nn.Linear(C,head_size,bias = False)\n",
        "query = nn.Linear(C,head_size,bias = True)\n",
        "value = nn.Linear(C,head_size,bias = False)\n",
        "k = key(x) #(B,T,head_size)\n",
        "q = key(x)\n",
        "wei = q@k.transpose(-2,-1) # (B,T,16)@(B,16,T)--> (B,T,T)\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "# wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei,dim =-1)\n",
        "v = value(x) #(B,T,head_size)\n",
        "out = wei@v\n",
        "out.shape #(B,T,head_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zeDN-YJsBPUn"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(config['n_embd'],config['head_size'],bias = False)\n",
        "    self.query = nn.Linear(config['n_embd'],config['head_size'],bias = True)\n",
        "    self.value = nn.Linear(config['n_embd'],config['head_size'],bias = False)\n",
        "    self.register_buffer('tril',torch.tril(torch.ones(config['block_size'],config['block_size'])))\n",
        "\n",
        "  def forward(self,x):\n",
        "    B,T,C = x.shape\n",
        "    k = self.key(x) #(B,T,head_size)\n",
        "    q = self.query(x)\n",
        "    wei = q@k.transpose(-2,-1)*C**-0.5\n",
        "    wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf'))\n",
        "    wei = F.softmax(wei,dim =-1)\n",
        "    v = self.value(x)\n",
        "    out = wei@v\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "74y5ECTMNkoY"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(config) for _ in range(config['num_head'])])\n",
        "\n",
        "  def forward(self,x):\n",
        "    return torch.cat([h(x) for h in self.heads],dim = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "esSDExFCP1KN"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(config['n_embd'],config['n_embd']),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "CmzBTPE25FO_"
      },
      "outputs": [],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.vocab_size = config['vocab_size']\n",
        "    self.n_embd = config['n_embd']\n",
        "    self.token_emb_table = nn.Embedding(self.vocab_size,self.n_embd)\n",
        "    self.block_size = config['block_size']\n",
        "    self.lm_head = nn.Linear(self.n_embd,self.vocab_size)\n",
        "    self.pos_embedding_table = nn.Embedding(self.block_size,self.n_embd)\n",
        "    self.sa_head = MultiHeadAttention(config)\n",
        "    self.ffwd = FeedForward(config)\n",
        "\n",
        "  def forward(self,idx,target=None):\n",
        "    B,T = idx.shape\n",
        "    pos_emb = self.pos_embedding_table(torch.arange(T)) #(T,n_embd)\n",
        "    tok_emb = self.token_emb_table(idx) # (B,T,n_embd)\n",
        "    x = tok_emb+pos_emb #(B,T,n_embd)\n",
        "    x = self.sa_head(x) # (B,T,vocab_size)\n",
        "    x = self.ffwd(x)\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "    if target is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B,T,C = logits.shape\n",
        "      logits = logits.view(B*T,C)\n",
        "      target = target.view(-1)\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      loss = criterion(logits,target)\n",
        "    return logits,loss\n",
        "\n",
        "  def generate(self,idx,config):\n",
        "    for i in range(config['max_tokens']):\n",
        "      idx_cond = idx[:, -config['block_size']:] # truncate to block_size\n",
        "      logits,_ = self(idx_cond)\n",
        "      logits = logits[:,-1,:]\n",
        "      probs = F.softmax(logits,dim=1)\n",
        "      idx_next = torch.multinomial(probs,num_samples=1)\n",
        "      idx = torch.cat((idx,idx_next),dim = 1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9lCPliJ_L2ZH"
      },
      "outputs": [],
      "source": [
        "blm = BigramLanguageModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf5qKAgGHZlJ",
        "outputId": "774bdc2f-45eb-4450-9adc-6fd5b35086d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.030078172683716\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = torch.optim.AdamW(blm.parameters(),lr = config['lr'])\n",
        "batching = Batching(train_data,val_data,config)\n",
        "for steps in range(config['epochs']):\n",
        "    xb,yb = batching(\"train\")\n",
        "\n",
        "    logits,loss = blm(xb,yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bY_M5jrMBbF",
        "outputId": "de5ad89f-4341-44d8-8477-0edb5e67dc09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "At sws all ank mny is they nart thir fake sinfousene; hou ing hime cet I to am, thatitke derow mant of gor read ith mur, his ride ban hill bespinopur:\n",
            "O with that un, youst hat ren.\n",
            "\n",
            "POLIS bre buruage;\n",
            "Kyround trione I gike tose, 't chougathmot cliens imm, mand suntly liat thamense angre:\n",
            "Sitee, youls, corsonty swellitelt with hacis.\n",
            "\n",
            "Whe vout mar wagughtess you affe, erive the hile donttecht I of nash, the not ad witg; ga hil enandle.\n",
            "\n",
            "QUEERIV:\n",
            "Aank intrijenarawrave will compothen\n",
            "that, nige to gaw, comeseewsapenst:\n",
            "To same allade lot man shawd alenglliis wout:\n",
            "That creave Ehound: I Cliugh's chavedas, his ake, my litheat that\n",
            "Whe tang that,\n",
            "Whe furre onin, in a me lins the the ducht; groveanmidly,\n",
            "Ou, thate sis the wir to my son\n",
            "And acky'd uppand Butohe fatudyre do, usold,\n",
            "And egrerdind'd youghesppob forone font cake this watin et wrezille brew'd\n",
            "Thate saing hith. LOM:\n",
            "EUSIUUS:\n",
            "Ways, I ay gruoht reeat the angivert's bleas son\n",
            "Thas mankradubleabre?\n",
            "\n",
            "PUUT:\n",
            "He thy, that servow dand prav\n"
          ]
        }
      ],
      "source": [
        "idx = torch.zeros((1,1),dtype = torch.long)\n",
        "print(tokenizer.decode(blm.generate(idx,config)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZrvGDDemM9Ac"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
